{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zilin/miniconda3/envs/test-1/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# https://datascienceub.medium.com/pointnet-implementation-explained-visually-c7e300139698\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zilin/miniconda3/envs/test-1/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset, convert to binary pixel values\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Lambda(lambda x: torch.where(x > 0,1,0))\n",
    "                             ]))\n",
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=64, shuffle=False)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Lambda(lambda x: torch.where(x > 0,1,0))\n",
    "                             ]))\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform image to 3D (x, y, binary value)\n",
    "def img_to_3d(img):\n",
    "    # get coordinates of pixels\n",
    "    coords_x, coords_y = torch.meshgrid(torch.arange(0, img.size(1)), torch.arange(0, img.size(2)))\n",
    "    coords_x = coords_x.flatten().float().unsqueeze(1)\n",
    "    coords_y = coords_y.flatten().float().unsqueeze(1)\n",
    "    values = img.view(-1).unsqueeze(1)\n",
    "    pc = torch.cat((coords_x, coords_y, values), dim=1)\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "  \n",
    "class TransformationNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TransformationNet, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv_2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv_3 = nn.Conv1d(128, 256, 1)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(64)\n",
    "        self.bn_2 = nn.BatchNorm1d(128)\n",
    "        self.bn_3 = nn.BatchNorm1d(256)\n",
    "        self.bn_4 = nn.BatchNorm1d(256)\n",
    "        self.bn_5 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.fc_1 = nn.Linear(256, 256)\n",
    "        self.fc_2 = nn.Linear(256, 128)\n",
    "        self.fc_3 = nn.Linear(128, self.output_dim*self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        num_points = x.shape[1]\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv_2(x)))\n",
    "        x = F.relu(self.bn_3(self.conv_3(x)))\n",
    "\n",
    "        x = nn.MaxPool1d(num_points)(x)\n",
    "        x = x.view(-1, 256)\n",
    "\n",
    "        x = F.relu(self.bn_4(self.fc_1(x)))\n",
    "        x = F.relu(self.bn_5(self.fc_2(x)))\n",
    "        x = self.fc_3(x)\n",
    "\n",
    "        identity_matrix = torch.eye(self.output_dim)\n",
    "        if torch.cuda.is_available():\n",
    "            identity_matrix = identity_matrix.cuda()\n",
    "        x = x.view(-1, self.output_dim, self.output_dim) + identity_matrix\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasePointNet(nn.Module):\n",
    "\n",
    "    def __init__(self, point_dimension):\n",
    "        super(BasePointNet, self).__init__()\n",
    "        self.input_transform = TransformationNet(input_dim=point_dimension, output_dim=point_dimension)\n",
    "        self.feature_transform = TransformationNet(input_dim=64, output_dim=64)\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(point_dimension, 64, 1)\n",
    "        self.conv_2 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv_3 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv_4 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv_5 = nn.Conv1d(128, 256, 1)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(64)\n",
    "        self.bn_2 = nn.BatchNorm1d(64)\n",
    "        self.bn_3 = nn.BatchNorm1d(64)\n",
    "        self.bn_4 = nn.BatchNorm1d(128)\n",
    "        self.bn_5 = nn.BatchNorm1d(256)\n",
    "        \n",
    "\n",
    "    def forward(self, x, plot=False):\n",
    "        num_points = x.shape[1]\n",
    "        \n",
    "        input_transform = self.input_transform(x) # T-Net tensor [batch, 3, 3]\n",
    "        x = torch.bmm(x, input_transform) # Batch matrix-matrix product \n",
    "        x = x.transpose(2, 1) \n",
    "        tnet_out=x.cpu().detach().numpy()\n",
    "        \n",
    "        x = F.relu(self.bn_1(self.conv_1(x)))\n",
    "        x = F.relu(self.bn_2(self.conv_2(x)))\n",
    "        x = x.transpose(2, 1)\n",
    "\n",
    "        feature_transform = self.feature_transform(x) # T-Net tensor [batch, 64, 64]\n",
    "        x = torch.bmm(x, feature_transform)\n",
    "        x = x.transpose(2, 1)\n",
    "        x = F.relu(self.bn_3(self.conv_3(x)))\n",
    "        x = F.relu(self.bn_4(self.conv_4(x)))\n",
    "        x = F.relu(self.bn_5(self.conv_5(x)))\n",
    "        x, ix = nn.MaxPool1d(num_points, return_indices=True)(x)  # max-pooling\n",
    "        x = x.view(-1, 256)  # global feature vector \n",
    "\n",
    "        return x, feature_transform, tnet_out, ix\n",
    "\n",
    "\n",
    "class ClassificationPointNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, dropout=0.3, point_dimension=3):\n",
    "        super(ClassificationPointNet, self).__init__()\n",
    "        self.base_pointnet = BasePointNet(point_dimension=point_dimension)\n",
    "\n",
    "        self.fc_1 = nn.Linear(256, 128)\n",
    "        self.fc_2 = nn.Linear(128, 64)\n",
    "        self.fc_3 = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.bn_1 = nn.BatchNorm1d(128)\n",
    "        self.bn_2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, feature_transform, tnet_out, ix_maxpool = self.base_pointnet(x)\n",
    "\n",
    "        x = F.relu(self.bn_1(self.fc_1(x)))\n",
    "        x = F.relu(self.bn_2(self.fc_2(x)))\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        return F.log_softmax(self.fc_3(x), dim=1), feature_transform, tnet_out, ix_maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationPointNet(num_classes=10,\n",
    "                                   point_dimension=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zilin/miniconda3/envs/test-1/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'return_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1948703/1965987216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtnet_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix_maxpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test-1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1948703/502319517.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtnet_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix_maxpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_pointnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test-1/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1948703/502319517.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, plot)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAvgPool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# max-pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# global feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'return_indices'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# training model\n",
    "epochs=80\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "best_loss= np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = []\n",
    "    epoch_train_acc = []\n",
    "\n",
    "    # training loop\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        batch_pc = []\n",
    "        for img in images:\n",
    "            batch_pc.append(img_to_3d(img))\n",
    "        pc = torch.stack(batch_pc, dim=0)\n",
    "        pc = pc.to(torch.float32).to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        model = model.train()\n",
    "        preds, feature_transform, tnet_out, ix_maxpool = model(pc)\n",
    "\n",
    "        identity = torch.eye(feature_transform.shape[-1])\n",
    "        identity = identity.to(device)\n",
    "        regularization_loss = torch.norm(\n",
    "            identity - torch.bmm(feature_transform, feature_transform.transpose(2, 1)))\n",
    "        # Loss\n",
    "        loss = F.nll_loss(preds, labels) + 0.001 * regularization_loss\n",
    "        epoch_train_loss.append(loss.cpu().item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        preds = preds.data.max(1)[1]\n",
    "        corrects = preds.eq(labels.data).cpu().sum()\n",
    "\n",
    "        accuracy = corrects.item() / float(images.size(0))\n",
    "        epoch_train_acc.append(accuracy)\n",
    "\n",
    "    epoch_test_loss = []\n",
    "    epoch_test_acc = []\n",
    "\n",
    "    # validation loop\n",
    "    for i, (val_images, val_labels) in enumerate(testloader):\n",
    "        val_batch_pc = []\n",
    "        for img in val_images:\n",
    "            val_batch_pc.append(img_to_3d(img))\n",
    "        val_pc = torch.stack(val_batch_pc, dim=0)\n",
    "        val_pc = val_pc.to(torch.float32).to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "        model = model.eval()\n",
    "        val_preds, feature_transform, tnet_out, ix = model(val_pc)\n",
    "        val_loss = F.nll_loss(val_preds, val_labels)\n",
    "        epoch_test_loss.append(val_loss.cpu().item())\n",
    "        val_preds = val_preds.data.max(1)[1]\n",
    "        corrects = val_preds.eq(val_labels.data).cpu().sum()\n",
    "        accuracy = corrects.item() / float(val_images.size(0))\n",
    "        epoch_test_acc.append(accuracy)\n",
    "\n",
    "    print('Epoch %s: train loss: %s, val loss: %f, train accuracy: %s,  val accuracy: %f'\n",
    "              % (epoch,\n",
    "                round(np.mean(epoch_train_loss), 4),\n",
    "                round(np.mean(epoch_test_loss), 4),\n",
    "                round(np.mean(epoch_train_acc), 4),\n",
    "                round(np.mean(epoch_test_acc), 4)))\n",
    "\n",
    "    if np.mean(test_loss) < best_loss:\n",
    "        state = {\n",
    "            'model':model.state_dict(),\n",
    "            'optimizer':optimizer.state_dict()\n",
    "        }\n",
    "        # torch.save(state, os.path.join('checkpoints', '3Dmnist_checkpoint_%s.pth' % (number_of_points)))\n",
    "        best_loss=np.mean(test_loss)\n",
    "\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    test_loss.append(np.mean(epoch_test_loss))\n",
    "    train_acc.append(np.mean(epoch_train_acc))\n",
    "    test_acc.append(np.mean(epoch_test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_point_net = \"/mnt/VOL1/zilin/diffusion-rnn/code/PointNet/Mar6_point_net_v2_AvgPool.pth\"\n",
    "torch.save(model.state_dict(), path_point_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
